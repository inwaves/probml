{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "female-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io, scipy.stats, scipy.linalg\n",
    "from numpy.linalg import solve\n",
    "import requests, io\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amateur-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.cl.cam.ac.uk/teaching/2122/DataSci/data/tennis_data.mat')\n",
    "with io.BytesIO(r.content) as f:\n",
    "    data = scipy.io.loadmat(f)\n",
    "    W = np.concatenate(data['W'].squeeze())\n",
    "    G = data['G'] - 1   # W[G[i,0]] is winner of game i, W[G[i,1]] is loser\n",
    "    M = W.shape[0]      # number of players M = 107\n",
    "    N = G.shape[0]      # number of games N = 1801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [10:12<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "pv = 0.75 * np.ones(M)   # prior variance\n",
    "w = np.zeros(M)         # skills, initialized to be the prior mean μ0 = 0\n",
    "skills_across_iterations = [w]\n",
    "\n",
    "for iteration in tqdm(range(1100)):\n",
    "    # Sample performance differences (t) given skills (w) and outcomes (G)\n",
    "    s = w[G[:,0]] - w[G[:,1]] # Deterministic skill difference.\n",
    "    σ = 1\n",
    "    \n",
    "    # Skill difference plus some noise epsilon.\n",
    "    t = s + σ * scipy.stats.norm.ppf(1 - np.random.uniform(size=N)*(1-scipy.stats.norm.cdf(-s/σ)))\n",
    "\n",
    "    # Sample skills given performance differences, i.e. \n",
    "    # Find some covariance and mean and distribute the new skills according to that.\n",
    "    inverse_Sigma_tilde = np.zeros((M, M))\n",
    "    mu_tilde = np.zeros(M)\n",
    "    \n",
    "    # This would compute each game precision matrix and add it to the inverse Σ~\n",
    "    # But here it just happens directly for conciseness.\n",
    "    for g in range(N):\n",
    "        inverse_Sigma_tilde[G[g, 0], G[g, 0]] += 1\n",
    "        inverse_Sigma_tilde[G[g, 1], G[g, 1]] += 1\n",
    "        inverse_Sigma_tilde[G[g, 0], G[g, 1]] -= 1\n",
    "        inverse_Sigma_tilde[G[g, 1], G[g, 0]] -= 1\n",
    "        \n",
    "    # Compute μ~: for all players i in M, for all games g in G, if the player won game g, add t[g], otherwise add -t[g] to mu_tilde[i]\n",
    "    for i in range(M):\n",
    "        for g in range(N):\n",
    "            if G[g, 0] == i:\n",
    "                mu_tilde[i] += t[g]\n",
    "            elif G[g, 1] == i:\n",
    "                mu_tilde[i] -= t[g]\n",
    "        \n",
    "    # Saving a call to np.linalg.inv by just inverting the diagonal covariance Sigma_0 directly.\n",
    "    Σinv = np.diag(1/pv) + inverse_Sigma_tilde\n",
    "    Σ = np.linalg.inv(Σinv)\n",
    "    μ = Σ @ mu_tilde\n",
    "    w = np.random.multivariate_normal(mean=μ, cov=Σ)\n",
    "    \n",
    "    # Storing results across iterations for plotting.\n",
    "    skills_across_iterations.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-london",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
